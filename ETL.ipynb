{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified ETL Pipeline\n",
    "\n",
    "This notebook reproduces the steps from the Python ETL scripts in a single,\n",
    "well-documented workflow. It generates the same output tables as the original\n",
    "scripts for ONET, AEI and CAGED data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import basedosdados as bd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "def strip_accents(text: str) -> str:\n",
    "    \"Return text without accent marks.\"\n",
    "    decomposed = unicodedata.normalize('NFKD', text)\n",
    "    return ''.join(ch for ch in decomposed if unicodedata.category(ch) != 'Mn')\n",
    "\n",
    "\n",
    "def merge_onet_soc_data() -> pd.DataFrame:\n",
    "    \"Merge O*NET task statements with SOC major group titles.\"\n",
    "    onet_df = pd.read_csv('data/input/aei_data/onet_task_statements.csv')\n",
    "    onet_df['soc_major_group'] = onet_df['O*NET-SOC Code'].str[:2]\n",
    "\n",
    "    soc_df = pd.read_csv('data/input/aei_data/SOC_Structure.csv')\n",
    "    soc_df = soc_df.dropna(subset=['Major Group'])\n",
    "    soc_df['soc_major_group'] = soc_df['Major Group'].str[:2]\n",
    "\n",
    "    merged = onet_df.merge(\n",
    "        soc_df[['soc_major_group', 'SOC or O*NET-SOC 2019 Title']],\n",
    "        on='soc_major_group',\n",
    "        how='left'\n",
    "    )\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "task_pct = pd.read_csv('data/input/aei_data/task_pct_v2.csv')\n",
    "automation_vs_augmentation_by_task = pd.read_csv(\n",
    "    'data/input/aei_data/automation_vs_augmentation_by_task.csv'\n",
    ")\n",
    "onet_tasks = pd.read_csv('data/input/aei_data/onet_task_statements.csv')\n",
    "soc_structure_aei = pd.read_csv('data/input/aei_data/SOC_Structure.csv')\n",
    "\n",
    "soc_structure_full = pd.read_csv('data/input/SOC_Structure.csv')\n",
    "\n",
    "caged_raw = pd.read_parquet('data/input/caged_national_UNTREATED.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ONET ETL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "soc_structure_full['minor_group'] = soc_structure_full.apply(\n",
    "    lambda row: row.dropna().iloc[0][:4], axis=1\n",
    ")\n",
    "minor_groups = (\n",
    "    soc_structure_full.groupby('minor_group')\n",
    "    .agg({'SOC or O*NET-SOC 2019 Title': lambda x: '; '.join(x)})\n",
    "    .rename({'SOC or O*NET-SOC 2019 Title': 'title'}, axis='columns')\n",
    ")\n",
    "minor_groups.to_csv('data/output/onet_minor_groups.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AEI ETL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "onet_with_soc = merge_onet_soc_data()\n",
    "onet_with_soc['task_normalized'] = onet_with_soc['Task'].str.lower().str.strip()\n",
    "\n",
    "onet_with_soc['n_occurrences'] = (\n",
    "    onet_with_soc.groupby('task_normalized')['Title'].transform('nunique')\n",
    ")\n",
    "\n",
    "grouped_with_occ = task_pct.merge(\n",
    "    onet_with_soc, left_on='task_name', right_on='task_normalized', how='left'\n",
    ")\n",
    "\n",
    "grouped_with_occ['pct_occ_scaled'] = 100 * (\n",
    "    grouped_with_occ['pct'] / grouped_with_occ['n_occurrences']\n",
    ") / (\n",
    "    grouped_with_occ['pct'] / grouped_with_occ['n_occurrences']\n",
    ").sum()\n",
    "\n",
    "automation_vs_augmentation_with_occ = grouped_with_occ.merge(\n",
    "    automation_vs_augmentation_by_task, on='task_name', how='left'\n",
    ")\n",
    "assert len(automation_vs_augmentation_with_occ) == len(grouped_with_occ)\n",
    "\n",
    "onet_tasks_tmp = onet_tasks[['O*NET-SOC Code', 'Task']].copy()\n",
    "onet_tasks_tmp['soc_minor_group'] = onet_tasks_tmp['O*NET-SOC Code'].str[:4]\n",
    "onet_tasks_tmp['task_name'] = onet_tasks_tmp['Task'].str.lower().str.strip()\n",
    "onet_tasks_tmp = onet_tasks_tmp[['soc_minor_group', 'task_name']].drop_duplicates()\n",
    "\n",
    "df = task_pct.merge(automation_vs_augmentation_by_task, on='task_name', how='left')\n",
    "df.fillna(0, inplace=True)\n",
    "df['aug'] = (df['learning'] + df['validation']) * df['pct']\n",
    "df['aut'] = (df['feedback_loop'] + df['directive'] + df['task_iteration']) * df['pct']\n",
    "df.drop(columns=['learning', 'validation', 'feedback_loop', 'directive', 'task_iteration'], inplace=True)\n",
    "\n",
    "df = df.merge(onet_tasks_tmp, on='task_name', how='left')\n",
    "occ_aut_aug_lvl = df.groupby('soc_minor_group')[['pct', 'aug', 'aut']].sum().reset_index()\n",
    "occ_aut_aug_lvl['aug_aut_ratio'] = occ_aut_aug_lvl['aug'] / occ_aut_aug_lvl['aut']\n",
    "occ_aut_aug_lvl.to_parquet('data/output/occ_aut_aug_lvl.parquet')\n",
    "\n",
    "top_10_pct = occ_aut_aug_lvl.sort_values('pct', ascending=False).head(10)\n",
    "top_10_pct['class'] = 'Top 10 pct'\n",
    "\n",
    "bottom_10_pct = occ_aut_aug_lvl.sort_values('pct', ascending=True).head(10)\n",
    "bottom_10_pct['class'] = 'Bottom 10 pct'\n",
    "\n",
    "top_10_aut = occ_aut_aug_lvl.sort_values('aut', ascending=False).head(10)\n",
    "top_10_aut['class'] = 'Top 10 aut'\n",
    "\n",
    "top_10_aug = occ_aut_aug_lvl.sort_values('aug', ascending=False).head(10)\n",
    "top_10_aug['class'] = 'Top 10 aug'\n",
    "\n",
    "classified = pd.concat([top_10_pct, bottom_10_pct, top_10_aut, top_10_aug])\n",
    "classified.to_parquet('data/output/occ_aut_aug_lvl_classified.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CAGED ETL"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Example query using basedosdados (already executed offline)\n",
    "# billing_id = os.getenv('BILLING_ID')\n",
    "# with open('data/config/caged_bd_national.SQL') as f:\n",
    "#     query = f.read()\n",
    "# df = bd.read_sql(query=query, billing_project_id=billing_id)\n",
    "# df.to_parquet('data/input/caged_national_UNTREATED.parquet')\n",
    "\n",
    "df = caged_raw.copy()\n",
    "df = df[~df['cbo_2002_descricao_subgrupo_principal'].isna()]\n",
    "\n",
    "cols_to_keep = [\n",
    "    'ano',\n",
    "    'mes',\n",
    "    'cbo_2002_descricao_subgrupo_principal',\n",
    "    'cbo_2002_descricao_grande_grupo'\n",
    "]\n",
    "\n",
    "df = (\n",
    "    df.groupby(cols_to_keep, dropna=False)['saldo_movimentacao']\n",
    "    .sum()\n",
    "    .reset_index()\n",
    "    .apply(lambda col: col.str.strip() if col.dtype == 'object' else col)\n",
    ")\n",
    "\n",
    "df = df.rename(\n",
    "    columns={\n",
    "        'saldo_movimentacao': 'net_jobs',\n",
    "        'ano': 'year',\n",
    "        'mes': 'month',\n",
    "        'cbo_2002_descricao_subgrupo_principal': 'cbo_subgroup',\n",
    "        'cbo_2002_descricao_grande_grupo': 'cbo_group'\n",
    "    }\n",
    ")\n",
    "\n",
    "df['cbo_subgroup'] = df['cbo_subgroup'].apply(strip_accents)\n",
    "df['cbo_group'] = df['cbo_group'].apply(strip_accents)\n",
    "\n",
    "df.to_parquet('data/input/caged_national.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
